{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“¦ Setup: Kaggle + AutoGluon Environment\n",
        "This cell installs the minimal dependencies (`kaggle`, `autogluon.tabular`), authenticates using my `kaggle.json` from Google Drive, and downloads the **California Housing Prices** dataset from Kaggle.  \n",
        "It also creates folders to store models and outputs so the workflow can run start-to-finish in Colab."
      ],
      "metadata": {
        "id": "w3en2vfumpKB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wrn2BBrZyfx",
        "outputId": "a4015b70-d76e-4c03-8b65-f24e58b11c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition: california-house-prices\n",
            "DATA_DIR: /content/data\n",
            "AUTOGLUON_SAVE_PATH: /content/data/AutoGluonModels\n",
            "Mounted at /content/drive\n",
            "Downloading california-house-prices.zip to /content/data\n",
            "  0% 0.00/29.5M [00:00<?, ?B/s]\n",
            "100% 29.5M/29.5M [00:00<00:00, 1.08GB/s]\n",
            "total 86M\n",
            "-rw-r--r-- 1 root root 248K Mar 19  2021 sample_submission.csv\n",
            "-rw-r--r-- 1 root root  35M Mar 19  2021 test.csv\n",
            "-rw-r--r-- 1 root root  51M Mar 19  2021 train.csv\n"
          ]
        }
      ],
      "source": [
        "# --- Colab setup: Kaggle competition + AutoGluon Tabular ---\n",
        "import os\n",
        "\n",
        "# ---- CONFIG ----\n",
        "KAGGLE_COMPETITION = \"california-house-prices\"\n",
        "DATA_DIR = \"/content/data\"\n",
        "DATASET = os.path.join(DATA_DIR, KAGGLE_COMPETITION)\n",
        "AUTOGLUON_SAVE_PATH = os.path.join(DATA_DIR, \"AutoGluonModels\")\n",
        "\n",
        "print(\"Competition:\", KAGGLE_COMPETITION)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"AUTOGLUON_SAVE_PATH:\", AUTOGLUON_SAVE_PATH)\n",
        "\n",
        "# ---- Install slim AutoGluon + Kaggle CLI ----\n",
        "!pip install -q kaggle autogluon.tabular scikit-learn\n",
        "\n",
        "# ---- Kaggle auth (assumes kaggle.json exists in Google Drive) ----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# ---- Download + extract competition files ----\n",
        "!mkdir -p \"{DATA_DIR}\" \"{AUTOGLUON_SAVE_PATH}\"\n",
        "!kaggle competitions download -c \"{KAGGLE_COMPETITION}\" -p \"{DATA_DIR}\" --force\n",
        "!unzip -o -q \"{DATA_DIR}/{KAGGLE_COMPETITION}.zip\" -d \"{DATA_DIR}/{KAGGLE_COMPETITION}\"\n",
        "!rm -f \"{DATA_DIR}/{KAGGLE_COMPETITION}.zip\"\n",
        "!ls -lh \"{DATA_DIR}/{KAGGLE_COMPETITION}\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ¤– Fast Training on 20 K Sample\n",
        "Here I load the housing dataset, take a **20 000-row sample** for a fast academic demonstration, and apply lightweight preprocessing: drop `Id`, log-scale numeric features, and use **LightGBM only** for quick training.  \n",
        "After training, AutoGluon predicts home prices on the full test set, reverses the log transform, and saves the predictions as `submission.csv`."
      ],
      "metadata": {
        "id": "b_FwGHRsmx_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cR27zLEeY68",
        "outputId": "61d95779-c06e-4c63-b0a0-8779401d22b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.28 GB / 12.67 GB (89.1%)\n",
            "Disk Space Avail:   186.24 GB / 225.83 GB (82.5%)\n",
            "===================================================\n",
            "Presets specified: ['medium_quality']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (16200, 40), Dev: (1800, 40), Holdout: (2000, 40)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ... Time limit = 300s\n",
            "AutoGluon will save models to \"/content/data/AutoGluonModels/california_house_20251014_235349\"\n",
            "Train Data Rows:    16200\n",
            "Train Data Columns: 39\n",
            "Tuning Data Rows:    1800\n",
            "Tuning Data Columns: 39\n",
            "Label Column:       Sold Price\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (17.909855136853043, 11.51792295668052, 13.73669, 0.79778)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11623.01 MB\n",
            "\tTrain Data (Original)  Memory Usage: 37.07 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', 'Bedrooms', 'Elementary School', 'Middle School', 'High School', 'Flooring', 'Heating features', 'Cooling features', 'Appliances included', 'Laundry features', 'Parking features']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                      : 18 | ['Year built', 'Lot', 'Bathrooms', 'Full bathrooms', 'Total interior livable area', ...]\n",
            "\t\t('object', [])                     :  4 | ['Type', 'Region', 'City', 'State']\n",
            "\t\t('object', ['datetime_as_object']) :  2 | ['Listed On', 'Last Sold On']\n",
            "\t\t('object', ['text'])               : 15 | ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :    3 | ['Type', 'Region', 'City']\n",
            "\t\t('category', ['text_as_category'])  :   15 | ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', ...]\n",
            "\t\t('float', [])                       :   18 | ['Year built', 'Lot', 'Bathrooms', 'Full bathrooms', 'Total interior livable area', ...]\n",
            "\t\t('int', ['binned', 'text_special']) :  181 | ['Address.char_count', 'Address.word_count', 'Address.capital_ratio', 'Address.lower_ratio', 'Address.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :    1 | ['State']\n",
            "\t\t('int', ['datetime_as_int'])        :   10 | ['Listed On', 'Listed On.year', 'Listed On.month', 'Listed On.day', 'Listed On.dayofweek', ...]\n",
            "\t\t('int', ['text_ngram'])             : 8877 | ['__nlp__.00', '__nlp__.000', '__nlp__.000 in', '__nlp__.000 in april', '__nlp__.000 in august', ...]\n",
            "\t152.6s = Fit runtime\n",
            "\t39 features in original data used to generate 9105 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 312.28 MB (2.7% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 158.58s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'GBM': [{'num_boost_round': 200, 'learning_rate': 0.1, 'num_leaves': 31, 'random_state': 42, 'bagging_seed': 42, 'feature_fraction_seed': 42, 'data_random_seed': 42, 'num_threads': 1}],\n",
            "\t'CAT': [],\n",
            "\t'XGB': [],\n",
            "\t'RF': [],\n",
            "\t'XT': [],\n",
            "\t'NN_TORCH': [],\n",
            "}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM ... Training model for up to 141.42s of the 141.42s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=3.1/10.7 GB\n",
            "\t-0.2275\t = Validation score   (-root_mean_squared_error)\n",
            "\t46.54s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 141.42s of the 94.68s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t-0.2275\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 211.46s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 10352.8 rows/s (1800 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/data/AutoGluonModels/california_house_20251014_235349\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Holdout metrics (log-scale RMSE): {'root_mean_squared_error': np.float64(-0.1884125617346258), 'mean_squared_error': -0.03549929341940418, 'mean_absolute_error': -0.09152310644919366, 'r2': 0.9436067064340019, 'pearsonr': 0.9715009371785128, 'median_absolute_error': np.float64(-0.04761857970012873)}\n",
            "Skipping dollar-scale RMSE: got an unexpected keyword argument 'squared'\n",
            "âœ… Saved submission: /content/data/AutoGluonModels/california_house_20251014_235349/submission.csv\n"
          ]
        }
      ],
      "source": [
        "# === FAST MODE (Academic demo): California Housing ===\n",
        "import os, time, numpy as np, pandas as pd, random\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ---- Reproducible seed ----\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "COMP_DIR = DATASET\n",
        "TRAIN_PATH = os.path.join(COMP_DIR, \"train.csv\")\n",
        "TEST_PATH  = os.path.join(COMP_DIR, \"test.csv\")\n",
        "SUB_PATH   = os.path.join(COMP_DIR, \"sample_submission.csv\")\n",
        "\n",
        "N_TRAIN = 20_000    # 20k rows trained for speed\n",
        "TL = 300            # Limit training for demonstration\n",
        "\n",
        "train_full = pd.read_csv(TRAIN_PATH)\n",
        "test_df    = pd.read_csv(TEST_PATH)\n",
        "sub_df     = pd.read_csv(SUB_PATH)\n",
        "\n",
        "# âœ… use SEED here for deterministic sampling\n",
        "train_df = train_full.sample(n=min(N_TRAIN, len(train_full)), random_state=SEED).reset_index(drop=True)\n",
        "del train_full\n",
        "\n",
        "# ---- quick preprocess ----\n",
        "target = \"Sold Price\"\n",
        "if \"Id\" in train_df.columns: train_df.drop(columns=[\"Id\"], inplace=True)\n",
        "if \"Id\" in test_df.columns:  test_df.drop(columns=[\"Id\"], inplace=True)\n",
        "\n",
        "# log1p numerics (stable scale)\n",
        "for c in train_df.select_dtypes(include=[\"number\"]).columns:\n",
        "    if c != target:\n",
        "        train_df[c] = np.log1p(train_df[c].clip(lower=0))\n",
        "train_df[target] = np.log1p(train_df[target].clip(lower=0))\n",
        "for c in test_df.select_dtypes(include=[\"number\"]).columns:\n",
        "    test_df[c] = np.log1p(test_df[c].clip(lower=0))\n",
        "\n",
        "# ---- Explicit splits: dev (for tuning) and holdout (never seen in training) ----\n",
        "# 10% holdout, then 10% dev from remaining 90%\n",
        "train_full_split, holdout = train_test_split(train_df, test_size=0.10, random_state=SEED)\n",
        "train_split, dev_split    = train_test_split(train_full_split, test_size=0.10, random_state=SEED)\n",
        "print(f\"Train: {train_split.shape}, Dev: {dev_split.shape}, Holdout: {holdout.shape}\")\n",
        "\n",
        "# ---- single fast model (LightGBM) ----\n",
        "hyperparameters = {\n",
        "    \"GBM\": [{\n",
        "        \"num_boost_round\": 200,\n",
        "        \"learning_rate\": 0.1,\n",
        "        \"num_leaves\": 31,\n",
        "        \"random_state\": SEED,          # ensures deterministic splits\n",
        "        \"bagging_seed\": SEED,          # ensures bagging reproducibility\n",
        "        \"feature_fraction_seed\": SEED, # ensures consistent feature sampling\n",
        "        \"data_random_seed\": SEED,\n",
        "        \"num_threads\": 1,              # stricter reproducibility\n",
        "    }],\n",
        "    \"CAT\": [], \"XGB\": [], \"RF\": [], \"XT\": [], \"NN_TORCH\": []\n",
        "}\n",
        "\n",
        "# Propagate a seed into AutoGluonâ€™s fitting stage\n",
        "ag_args_fit = {\"random_seed\": SEED}\n",
        "\n",
        "# --- Use a fresh, unique run folder to avoid \"path already exists\" warning ---\n",
        "BASE_PATH = AUTOGLUON_SAVE_PATH\n",
        "os.makedirs(BASE_PATH, exist_ok=True)\n",
        "RUN_NAME = f\"california_house_{time.strftime('%Y%m%d_%H%M%S')}\"\n",
        "MODEL_PATH = os.path.join(BASE_PATH, RUN_NAME)\n",
        "\n",
        "predictor = TabularPredictor(\n",
        "    label=target,\n",
        "    eval_metric=\"rmse\",\n",
        "    path=MODEL_PATH,\n",
        "    verbosity=2\n",
        ")\n",
        "\n",
        "trained = False\n",
        "try:\n",
        "    predictor.fit(\n",
        "        train_data=train_split,\n",
        "        tuning_data=dev_split,\n",
        "        hyperparameters=hyperparameters,\n",
        "        presets='medium_quality',\n",
        "        time_limit=TL,\n",
        "        num_bag_folds=0,\n",
        "        num_stack_levels=0,\n",
        "        keep_only_best=True,\n",
        "        ag_args_fit=ag_args_fit,\n",
        "    )\n",
        "    trained = True\n",
        "except AssertionError as e:\n",
        "    print(\"âœ… Fit exited early (low time_limit):\", e)\n",
        "\n",
        "# ---- evaluate on truly unseen holdout ----\n",
        "if trained and getattr(predictor, \"_trainer\", None):\n",
        "    holdout_metrics = predictor.evaluate(holdout)\n",
        "    print(\"Holdout metrics (log-scale RMSE):\", holdout_metrics)\n",
        "\n",
        "    try:\n",
        "        from sklearn.metrics import mean_squared_error\n",
        "        y_true = np.expm1(holdout[target].values)\n",
        "        y_pred = np.expm1(predictor.predict(holdout))\n",
        "        rmse_dollars = mean_squared_error(y_true, y_pred, squared=False)\n",
        "        print(f\"Holdout RMSE (original $): {rmse_dollars:,.2f}\")\n",
        "    except Exception as e:\n",
        "        print(\"Skipping dollar-scale RMSE:\", e)\n",
        "\n",
        "    # ---- predict + submission ----\n",
        "    pred_log = predictor.predict(test_df)\n",
        "    pred = np.expm1(pred_log)\n",
        "    sub = sub_df.copy()\n",
        "    sub[\"Sold Price\"] = pred\n",
        "    out_path = os.path.join(MODEL_PATH, \"submission.csv\")\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print(\"âœ… Saved submission:\", out_path)\n",
        "else:\n",
        "    print(\"â¸ï¸ Training didnâ€™t complete â€” increase TL (â‰¥300 s).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸš€ Submit to Kaggle\n",
        "This cell uses the Kaggle CLI to submit the generated `submission.csv` to the **california-house-prices** competition.  \n",
        "It confirms the file exists, uploads it, and shows my recent submissions to verify a successful run."
      ],
      "metadata": {
        "id": "t3JOiJVVm3pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Submit to Kaggle competition ===\n",
        "import os\n",
        "\n",
        "COMPETITION = \"california-house-prices\"\n",
        "SUBMISSION_FILE = os.path.join(AUTOGLUON_SAVE_PATH, \"submission.csv\")\n",
        "MESSAGE = \"AutoGluon fast academic demo submission\"\n",
        "\n",
        "# Verify the submission file exists\n",
        "!ls -lh \"$SUBMISSION_FILE\"\n",
        "\n",
        "# Submit to Kaggle\n",
        "!kaggle competitions submit -c \"$COMPETITION\" -f \"$SUBMISSION_FILE\" -m \"$MESSAGE\"\n",
        "\n",
        "# Show recent submissions for confirmation\n",
        "!kaggle competitions submissions -c \"$COMPETITION\" | head -n 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUm49p61ZqFJ",
        "outputId": "3ea00556-9463-42aa-e5ab-d51da717a67a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/data/AutoGluonModels/submission.csv': No such file or directory\n",
            "[Errno 2] No such file or directory: '/content/data/AutoGluonModels/submission.csv'\n",
            "fileName        date                        description                              status                     publicScore  privateScore  \n",
            "--------------  --------------------------  ---------------------------------------  -------------------------  -----------  ------------  \n",
            "submission.csv  2025-10-14 18:58:22.137000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 18:52:46.223000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 18:45:58.970000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 18:38:27.617000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 18:20:55.297000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 18:08:38.413000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 17:58:13.473000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 17:49:41.267000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 15:46:24.810000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14474      0.13026       \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}