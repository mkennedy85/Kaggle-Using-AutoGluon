{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 📦 Setup: Kaggle + AutoGluon Environment\n",
        "This cell installs the minimal dependencies (`kaggle`, `autogluon.tabular`), authenticates using my `kaggle.json` from Google Drive, and downloads the **California Housing Prices** dataset from Kaggle.  \n",
        "It also creates folders to store models and outputs so the workflow can run start-to-finish in Colab."
      ],
      "metadata": {
        "id": "w3en2vfumpKB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wrn2BBrZyfx",
        "outputId": "36aa63f6-c5a6-410a-9818-7a8fe6a70639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition: california-house-prices\n",
            "DATA_DIR: /content/data\n",
            "AUTOGLUON_SAVE_PATH: /content/data/AutoGluonModels\n",
            "Mounted at /content/drive\n",
            "Downloading california-house-prices.zip to /content/data\n",
            "  0% 0.00/29.5M [00:00<?, ?B/s]\n",
            "100% 29.5M/29.5M [00:00<00:00, 977MB/s]\n",
            "total 86M\n",
            "-rw-r--r-- 1 root root 248K Mar 19  2021 sample_submission.csv\n",
            "-rw-r--r-- 1 root root  35M Mar 19  2021 test.csv\n",
            "-rw-r--r-- 1 root root  51M Mar 19  2021 train.csv\n"
          ]
        }
      ],
      "source": [
        "# --- Colab setup: Kaggle competition + AutoGluon Tabular ---\n",
        "import os\n",
        "\n",
        "# ---- CONFIG ----\n",
        "KAGGLE_COMPETITION = \"california-house-prices\"\n",
        "DATA_DIR = \"/content/data\"\n",
        "DATASET = os.path.join(DATA_DIR, KAGGLE_COMPETITION)\n",
        "AUTOGLUON_SAVE_PATH = os.path.join(DATA_DIR, \"AutoGluonModels\")\n",
        "\n",
        "print(\"Competition:\", KAGGLE_COMPETITION)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"AUTOGLUON_SAVE_PATH:\", AUTOGLUON_SAVE_PATH)\n",
        "\n",
        "# ---- Install slim AutoGluon + Kaggle CLI ----\n",
        "!pip install -q kaggle autogluon.tabular\n",
        "\n",
        "# ---- Kaggle auth (assumes kaggle.json exists in Google Drive) ----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# ---- Download + extract competition files ----\n",
        "!mkdir -p \"{DATA_DIR}\" \"{AUTOGLUON_SAVE_PATH}\"\n",
        "!kaggle competitions download -c \"{KAGGLE_COMPETITION}\" -p \"{DATA_DIR}\" --force\n",
        "!unzip -o -q \"{DATA_DIR}/{KAGGLE_COMPETITION}.zip\" -d \"{DATA_DIR}/{KAGGLE_COMPETITION}\"\n",
        "!rm -f \"{DATA_DIR}/{KAGGLE_COMPETITION}.zip\"\n",
        "!ls -lh \"{DATA_DIR}/{KAGGLE_COMPETITION}\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🤖 Fast Training on 20 K Sample\n",
        "Here I load the housing dataset, take a **20 000-row sample** for a fast academic demonstration, and apply lightweight preprocessing: drop `Id`, log-scale numeric features, and use **LightGBM only** for quick training.  \n",
        "After training, AutoGluon predicts home prices on the full test set, reverses the log transform, and saves the predictions as `submission.csv`."
      ],
      "metadata": {
        "id": "b_FwGHRsmx_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cR27zLEeY68",
        "outputId": "adcb3472-d698-4729-9f36-2c34190e45a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.27 GB / 12.67 GB (88.9%)\n",
            "Disk Space Avail:   185.86 GB / 225.83 GB (82.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
            "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ... Time limit = 300s\n",
            "AutoGluon will save models to \"/content/data/AutoGluonModels/california_house_20251014_181635\"\n",
            "Train Data Rows:    20000\n",
            "Train Data Columns: 39\n",
            "Label Column:       Sold Price\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (17.909855136853043, 11.51792295668052, 13.74036, 0.7982)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11582.00 MB\n",
            "\tTrain Data (Original)  Memory Usage: 41.18 MB (0.4% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', 'Bedrooms', 'Elementary School', 'Middle School', 'High School', 'Flooring', 'Heating features', 'Cooling features', 'Appliances included', 'Laundry features', 'Parking features']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                      : 18 | ['Year built', 'Lot', 'Bathrooms', 'Full bathrooms', 'Total interior livable area', ...]\n",
            "\t\t('object', [])                     :  4 | ['Type', 'Region', 'City', 'State']\n",
            "\t\t('object', ['datetime_as_object']) :  2 | ['Listed On', 'Last Sold On']\n",
            "\t\t('object', ['text'])               : 15 | ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :    3 | ['Type', 'Region', 'City']\n",
            "\t\t('category', ['text_as_category'])  :   15 | ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', ...]\n",
            "\t\t('float', [])                       :   18 | ['Year built', 'Lot', 'Bathrooms', 'Full bathrooms', 'Total interior livable area', ...]\n",
            "\t\t('int', ['binned', 'text_special']) :  181 | ['Address.char_count', 'Address.word_count', 'Address.capital_ratio', 'Address.lower_ratio', 'Address.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :    1 | ['State']\n",
            "\t\t('int', ['datetime_as_int'])        :   10 | ['Listed On', 'Listed On.year', 'Listed On.month', 'Listed On.day', 'Listed On.dayofweek', ...]\n",
            "\t\t('int', ['text_ngram'])             : 8941 | ['__nlp__.00', '__nlp__.000', '__nlp__.000 in', '__nlp__.000 in april', '__nlp__.000 in august', ...]\n",
            "\t147.7s = Fit runtime\n",
            "\t39 features in original data used to generate 9169 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 349.42 MB (3.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 152.9s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 18000, Val Rows: 2000\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'GBM': [{'num_boost_round': 200, 'learning_rate': 0.1, 'num_leaves': 31}],\n",
            "\t'CAT': [],\n",
            "\t'XGB': [],\n",
            "\t'RF': [],\n",
            "\t'XT': [],\n",
            "\t'NN_TORCH': [],\n",
            "}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM ... Training model for up to 147.10s of the 147.10s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=3.2/10.2 GB\n",
            "\t-0.1769\t = Validation score   (-root_mean_squared_error)\n",
            "\t53.62s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 147.10s of the 93.02s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t-0.1769\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 213.34s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4832.0 rows/s (2000 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/data/AutoGluonModels/california_house_20251014_181635\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved submission: /content/data/AutoGluonModels/california_house_20251014_181635/submission.csv\n"
          ]
        }
      ],
      "source": [
        "# === FAST MODE (Academic demo): California Housing ===\n",
        "import os, time, numpy as np, pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "COMP_DIR = DATASET\n",
        "TRAIN_PATH = os.path.join(COMP_DIR, \"train.csv\")\n",
        "TEST_PATH  = os.path.join(COMP_DIR, \"test.csv\")\n",
        "SUB_PATH   = os.path.join(COMP_DIR, \"sample_submission.csv\")\n",
        "\n",
        "N_TRAIN = 20_000    # 20k rows trained for speed\n",
        "TL = 300            # Limit training for demonstration\n",
        "\n",
        "train_full = pd.read_csv(TRAIN_PATH)\n",
        "test_df    = pd.read_csv(TEST_PATH)\n",
        "sub_df     = pd.read_csv(SUB_PATH)\n",
        "\n",
        "train_df = train_full.sample(n=min(N_TRAIN, len(train_full)), random_state=42).reset_index(drop=True)\n",
        "del train_full\n",
        "\n",
        "# ---- quick preprocess ----\n",
        "target = \"Sold Price\"\n",
        "if \"Id\" in train_df.columns: train_df.drop(columns=[\"Id\"], inplace=True)\n",
        "if \"Id\" in test_df.columns:  test_df.drop(columns=[\"Id\"], inplace=True)\n",
        "\n",
        "# log1p numerics (stable scale)\n",
        "for c in train_df.select_dtypes(include=[\"number\"]).columns:\n",
        "    if c != target:\n",
        "        train_df[c] = np.log1p(train_df[c].clip(lower=0))\n",
        "train_df[target] = np.log1p(train_df[target].clip(lower=0))\n",
        "for c in test_df.select_dtypes(include=[\"number\"]).columns:\n",
        "    test_df[c] = np.log1p(test_df[c].clip(lower=0))\n",
        "\n",
        "# ---- single fast model (LightGBM) ----\n",
        "hyperparameters = {\n",
        "    \"GBM\": [{\"num_boost_round\": 200, \"learning_rate\": 0.1, \"num_leaves\": 31}],\n",
        "    \"CAT\": [], \"XGB\": [], \"RF\": [], \"XT\": [], \"NN_TORCH\": []\n",
        "}\n",
        "\n",
        "# --- Use a fresh, unique run folder to avoid \"path already exists\" warning ---\n",
        "BASE_PATH = AUTOGLUON_SAVE_PATH\n",
        "os.makedirs(BASE_PATH, exist_ok=True)\n",
        "RUN_NAME = f\"california_house_{time.strftime('%Y%m%d_%H%M%S')}\"\n",
        "MODEL_PATH = os.path.join(BASE_PATH, RUN_NAME)\n",
        "\n",
        "predictor = TabularPredictor(\n",
        "    label=target,\n",
        "    eval_metric=\"rmse\",\n",
        "    path=MODEL_PATH,\n",
        "    verbosity=2\n",
        ")\n",
        "\n",
        "trained = False\n",
        "try:\n",
        "    predictor.fit(\n",
        "        train_data=train_df,\n",
        "        hyperparameters=hyperparameters,\n",
        "        presets=None,\n",
        "        time_limit=TL,\n",
        "        num_bag_folds=0,\n",
        "        num_stack_levels=0,\n",
        "        keep_only_best=True,\n",
        "    )\n",
        "    trained = True\n",
        "except AssertionError as e:\n",
        "    print(\"✅ Fit exited early (low time_limit):\", e)\n",
        "\n",
        "# ---- predict + submission ----\n",
        "if trained and getattr(predictor, \"_trainer\", None):\n",
        "    pred_log = predictor.predict(test_df)\n",
        "    pred = np.expm1(pred_log)\n",
        "    sub = sub_df.copy()\n",
        "    sub[\"Sold Price\"] = pred\n",
        "    out_path = os.path.join(MODEL_PATH, \"submission.csv\")\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print(\"✅ Saved submission:\", out_path)\n",
        "else:\n",
        "    print(\"⏸️ Training didn’t complete — increase TL (≥300 s).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🚀 Submit to Kaggle\n",
        "This cell uses the Kaggle CLI to submit the generated `submission.csv` to the **california-house-prices** competition.  \n",
        "It confirms the file exists, uploads it, and shows my recent submissions to verify a successful run."
      ],
      "metadata": {
        "id": "t3JOiJVVm3pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Submit to Kaggle competition ===\n",
        "import os\n",
        "\n",
        "COMPETITION = \"california-house-prices\"\n",
        "SUBMISSION_FILE = os.path.join(AUTOGLUON_SAVE_PATH, \"submission.csv\")\n",
        "MESSAGE = \"AutoGluon fast academic demo submission\"\n",
        "\n",
        "# Verify the submission file exists\n",
        "!ls -lh \"$SUBMISSION_FILE\"\n",
        "\n",
        "# Submit to Kaggle\n",
        "!kaggle competitions submit -c \"$COMPETITION\" -f \"$SUBMISSION_FILE\" -m \"$MESSAGE\"\n",
        "\n",
        "# Show recent submissions for confirmation\n",
        "!kaggle competitions submissions -c \"$COMPETITION\" | head -n 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUm49p61ZqFJ",
        "outputId": "5f2a543b-2270-4a8a-e2c6-c5c932784312"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 484K Oct 14 18:08 /content/data/AutoGluonModels/submission.csv\n",
            "100% 483k/483k [00:00<00:00, 1.17MB/s]\n",
            "Successfully submitted to California House PricesfileName        date                        description                              status                     publicScore  privateScore  \n",
            "--------------  --------------------------  ---------------------------------------  -------------------------  -----------  ------------  \n",
            "submission.csv  2025-10-14 18:20:55.297000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 18:08:38.413000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 17:58:13.473000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 17:49:41.267000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14620      0.13130       \n",
            "submission.csv  2025-10-14 15:46:24.810000  AutoGluon fast academic demo submission  SubmissionStatus.COMPLETE  0.14474      0.13026       \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}